version: 2.1

commands:

  abort_for_valgrind:
    steps:
      - run:
          name: Avoid running valgrind unless explicitly called
          command: |
            git log --format=oneline -n 1 $CIRCLE_SHA1|grep 'run valgrind' || circleci step halt

  abort_for_docs:
    steps:
      - run:
          name: Avoid tests for docs
          command: |
            if [[ $CIRCLE_BRANCH == *docs ]]; then
              echo "Identifies as documents PR, no testing required"
              circleci step halt
            fi

  early_return_for_forked_pull_requests:
    description: >-
      If this build is from a fork, stop executing the current job and return success.
      This is useful to avoid steps that will fail due to missing credentials.
    steps:
      - run:
          name: Early return if this build is from a forked PR
          command: |
            if [[ -n "$CIRCLE_PR_NUMBER" ]]; then
              echo "Nothing to do for forked PRs, so marking this step successful"
              circleci step halt
            fi

  setup-executor:
    steps:
      - run:
          name: Setup executor
          command: |
            sudo apt-get -qq update
            sudo apt-get -q install -y git openssh-client curl ca-certificates make tar gzip
            bash <(curl -fsSL https://get.docker.com)
#      - setup_remote_docker:
#          docker_layer_caching: true

  relocate-docker-storage:
    steps:
      - run:
          name: Relocate docker overlay2 dir
          command: |
            sudo systemctl stop docker
            sudo mkdir -p /var2/lib/docker
            sudo mv /var/lib/docker/overlay2 /var2/lib/docker
            sudo mkdir /var/lib/docker/overlay2
            sudo mount --bind /var2/lib/docker/overlay2 /var/lib/docker/overlay2
            sudo systemctl start docker

  setup-automation:
    steps:
      - run:
          name: Setup automation
          command: |
            git submodule update --init opt/readies
            ./opt/readies/bin/getpy3

  setup-build-system:
    steps:
      - setup-automation
      - run:
          name: Setup build system
          command: |
            ./opt/system-setup.py

  checkout-all:
    steps:
      - checkout
      - run:
          name: Checkout submodules
          command: git submodule update --init --recursive

  build-steps:
    parameters:
      platform:
        type: string
    steps:
      - abort_for_docs
      - checkout-all
      - restore_cache:
          keys:
          - v1-dependencies-{{ checksum "get_deps.sh" }}
          # If no exact match is found will get dependencies from source
      - setup-build-system
      - run:
          name: Install dependencies
          command: |
            ./opt/readies/bin/getredis -v 6 --force
            ./get_deps.sh cpu
      - save_cache:
          paths:
            - deps
          key: build-dependencies-{{ checksum "get_deps.sh" }}
      - run:
          name: Build
          command: make -C opt all SHOW=1
      - run:
          name: Unit Tests
          command: |
            make -C opt unit_tests SHOW=1
          no_output_timeout: 5m
      - run:
          name: Test
          command: |
            make -C opt test SHOW=1
          no_output_timeout: 20m
      - run:
          name: Package
          command: |
            make -C opt pack SHOW=1
            (cd bin/artifacts; tar -cf snapshots-<<parameters.platform>>.tar snapshots/)
      - persist_to_workspace:
          root: bin/
          paths:
            - artifacts/*.zip
            - artifacts/*.tgz
            - artifacts/*.tar
      - store_artifacts:
          path: tests/logs

  platforms-build-steps:
    steps:
      - early_return_for_forked_pull_requests
      - abort_for_docs
      - checkout-all
      - relocate-docker-storage
      - setup-automation
      - run:
          name: Build for platform
          command: |
            pushd opt/build/docker
            docker login -u redisfab -p $DOCKER_REDISFAB_PWD
            for osnick in bionic xenial; do
                make CPU=1 OSNICK=$osnick ARTIFACTS=1 VERBOSE=1 build publish
                make GPU=1 OSNICK=$osnick ARTIFACTS=1 VERBOSE=1 build publish
                docker image prune -f
            done
            popd > /dev/null
            logstar=bin/artifacts/tests-logs-cpu.tgz
            logsdir=tests/logs/cpu
            mkdir -p $logsdir
            if [[ -e $logstar ]]; then tar -C $logsdir -xzf $logstar; fi
            (cd bin/artifacts; tar -cf snapshots.tar snapshots/)
          no_output_timeout: 40m
      - persist_to_workspace:
          root: bin/
          paths:
            - artifacts/*.zip
            - artifacts/*.tgz
            - artifacts/*.tar
      - store_artifacts:
          path: test/logs

  deploy-steps:
    parameters:
      from:
        type: string
    steps:
      - abort_for_docs
      - early_return_for_forked_pull_requests
      - run:
          name: Deploy to S3
          command: |
            du -ah --apparent-size artifacts/*
            aws s3 cp artifacts/ s3://redismodules/$PACKAGE_NAME/ --acl public-read --recursive --exclude "*" --include "*.zip" --include "*.tgz"

jobs:
  lint:
    docker:
      - image: redislabsmodules/llvm-toolset:latest
    steps:
      - checkout-all
      - setup-build-system
      - run:
          name: lint
          command: |
            make -C opt lint

  build-and-test:
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - build-steps:
          platform: debian

  # this build runs on a fixed machine, due to a storage need
  # nothing about it necessitates the machine itself, other than the need for more disk.
  platforms-build:
    machine:
      enabled: true
      docker_layer_caching: true
      resource_class: medium
      image: ubuntu-2004:202101-01
    steps:
      - platforms-build-steps

  coverage:
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - abort_for_docs
      - checkout-all
      - restore_cache:
          keys:
          - build-dependencies-{{ checksum "get_deps.sh" }}
          # If no exact match is found will get dependencies from source
      - setup-build-system
      - run:
          name: Install dependencies
          command: |
            ./opt/readies/bin/getredis -v 6 --valgrind --force
            ./get_deps.sh cpu
      - run:
          name: Build for coverage
          command: |
            make -C opt all COV=1 SHOW=1
      - run:
          name: Test with coverage
          command: |
            make -C opt test SHOW=1 COV=1 CLUSTER=1
            make -C opt cov-upload
          no_output_timeout: 30m

  valgrind:
    parameters:
      test_args:
        type: string
        default: "CLUSTER=0 AOF=0"
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - abort_for_docs
      - checkout-all
      - restore_cache:
          keys:
          - build-dependencies-{{ checksum "get_deps.sh" }}
          # If no exact match is found will get dependencies from source
      - setup-build-system
      - run:
          name: Install dependencies
          command: |
            ./opt/readies/bin/getredis -v 6.0 --valgrind --force
            ./get_deps.sh cpu
      - run:
          name: Build for valgrind
          command: |
            make -C opt all VALGRIND=1 SHOW=1
      - run:
          name: Test with valgrind
          command: |
            make -C opt test VALGRIND=1 <<parameters.test_args>>
          no_output_timeout: 120m

  valgrind-general:
    parameters:
      test_args:
        type: string
        default: "CLUSTER=0 AOF=0"
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - early_return_for_forked_pull_requests
      - abort_for_docs
      - checkout-all
      - restore_cache:
          keys:
          - build-dependencies-{{ checksum "get_deps.sh" }}
          # If no exact match is found will get dependencies from source
      - setup-build-system
      - run:
          name: Install dependencies
          command: |
            ./opt/readies/bin/getredis -v 6.0 --valgrind --force
            ./get_deps.sh cpu
      - run:
          name: Build for valgrind
          command: |
            make -C opt all VALGRIND=1 SHOW=1
      - run:
          name: Test with valgrind
          command: |
            make -C opt test VALGRIND=1 <<parameters.test_args>>
          no_output_timeout: 120m

#  build-macos:
#    macos:
#      xcode: 11.3.0
#    steps:
#      - abort_for_docs
#      - run:
#          name: Fix macOS Python installation
#          command: |
#            brew reinstall -f python2
#      - build-steps:
#          platform: macos
#
#  build-multiarch-docker:
#    machine:
#      enabled: true
#      image: cimg/base:2020.01
#    steps:
#      - abort_for_docs
#      - checkout-all
#      - run:
#          name: Checkout LFS
#          command: |
#            curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
#            sudo apt-get install -y git-lfs
#            git lfs install
#            git lfs pull
#      - run:
#          name: Setup Docker client experimental features
#          command: |
#            sudo ./opt/readies/bin/getdocker --just-enable-exp
#            docker version
#      - run:
#          name: Build
#          command: |
#            sudo docker login -u redisfab -p $DOCKER_REDISFAB_PWD
#            cd opt/build/docker
#            make build
#            sudo make publish

  build-and-test-gpu:
    machine:
      enabled: true
      docker_layer_caching: true
      resource_class: gpu.nvidia.small
      image: ubuntu-1604-cuda-11.1:202012-01

    steps:
      - abort_for_docs
      - checkout-all
      - run:
          name: Relocate docker overlay2 dir
          command: |
            sudo systemctl stop docker
            sudo mkdir -p /var2/lib/docker
            sudo mv /var/lib/docker/overlay2 /var2/lib/docker
            sudo mkdir /var/lib/docker/overlay2
            sudo mount --bind /var2/lib/docker/overlay2 /var/lib/docker/overlay2
            sudo systemctl start docker
      - run:
          name: Build
          command: |
            docker build -f Dockerfile.gpu-test --no-cache -t redisai-gpu:latest-x64-bionic-test .
      - run:
          name: Test
          command: |
            mkdir -p $HOME/tests
            docker run --gpus all -v $HOME/tests:/build/tests/logs -it --rm redisai-gpu:latest-x64-bionic-test
          no_output_timeout: 40m
      - store_artifacts:
          path: tests/logs

  deploy-artifacts:
    parameters:
      location:
        type: string
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - abort_for_docs
      - early_return_for_forked_pull_requests
      - attach_workspace:
          at: workspace
      - run:
          name: Deploy to S3
          command: |
            cd "workspace/artifacts/<<parameters.location>>"
            du -ah --apparent-size *
            for f in *.zip snapshot/*.tgz; do
              aws s3 cp $f s3://redismodules/$PACKAGE_NAME/<<parameters.location>>/ --acl public-read
            done

  deploy-snapshot:
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - abort_for_docs
      - early_return_for_forked_pull_requests
      - attach_workspace:
          at: workspace
      - run:
          name: Deploy Snapshots to S3
          command: |
            cd workspace/artifacts
            for f in snapshots*.tar; do
                echo "Extracting $f ..."
                tar xf $f
            done
            echo "... done."
            du -ah --apparent-size *
            cd snapshots
            for f in `ls *.zip *.tgz`; do
              aws s3 cp --no-progress $f s3://redismodules/$PACKAGE_NAME/snapshots/ --acl public-read
            done

  deploy-release:
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - abort_for_docs
      - early_return_for_forked_pull_requests
      - attach_workspace:
          at: workspace
      - run:
          name: Deploy Releases to S3
          command: |
            cd workspace/artifacts
            du -ah --apparent-size *
            for f in `ls *.zip *.tgz`; do
              aws s3 cp --no-progress $f s3://redismodules/$PACKAGE_NAME/ --acl public-read
            done

  release-automation:
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - checkout
      - setup-automation
      - run:
          name: Run QA Automation
          command: MODULE_VERSION=$CIRCLE_TAG VERBOSE=1 TEST=release ./tests/qa/run

  nightly-automation:
    docker:
      - image: redisfab/rmbuilder:6.2.1-x64-buster
    steps:
      - checkout
      - setup-automation
      - run:
          name: Run QA Automation
          command: MODULE_VERSION=$CIRCLE_BRANCH VERBOSE=1 TEST=nightly QUICK=1 ./tests/qa/run


on-any-branch: &on-any-branch
  filters:
    branches:
      only: /.*/
    tags:
      only: /.*/

on-any-branch-but-tags: &on-any-branch-but-tags
  filters:
    branches:
      only: /.*/
    tags:
      ignore: /.*/

never: &never
  filters:
    branches:
      ignore: /.*/
    tags:
      ignore: /.*/

on-master: &on-master
  filters:
    branches:
      only: master
    tags:
      ignore: /.*/

on-integ-branch: &on-integ-branch
  filters:
    branches:
      only:
        - master
        - /^\d+\.\d+.*$/
    tags:
      ignore: /.*/

on-dev-branches: &on-dev-branches
  filters:
    branches:
      ignore:
        - master
        - /^\d+\.\d+.*$/
    tags:
      ignore: /.*/

on-version-tags: &on-version-tags
  filters:
    branches:
      ignore: /.*/
    tags:
      only: /^v[0-9].*/

on-master-and-version-tags: &on-master-and-version-tags
  filters:
    branches:
      only:
        - master
    tags:
      only: /^v[0-9].*/


after-linter: &after-linter
  requires:
    - lint

after-build-and-test: &after-build-and-test
  requires:
    - build-and-test

after-platform-builds: &after-platform-builds
  requires:
    - platforms-build

#### define workflows
workflows:
  version: 2
  build_and_package:
    jobs:
      - lint:
          <<: *on-any-branch
      - build-and-test:
          <<: *on-any-branch-but-tags
          <<: *after-linter
      - platforms-build:
          <<: *after-build-and-test
          <<: *on-master-and-version-tags
      - coverage:
          context: common
          <<: *on-dev-branches
          <<: *after-linter
      - valgrind:
          name: valgrind-cluster
          test_args: GEN=0 AOF=0
          <<: *on-integ-branch
          <<: *after-linter
      - valgrind:
          name: valgrind-aof
          test_args: GEN=0 CLUSTER=0
          <<: *on-integ-branch
          <<: *after-linter
      - build-and-test-gpu:
          <<: *on-integ-branch
          <<: *after-linter
      - deploy-snapshot:
          context: common
          <<: *after-platform-builds
          <<: *on-integ-branch
      - deploy-release:
          context: common
          <<: *after-platform-builds
          <<: *on-version-tags
      - release-automation:
          context: common
          <<: *on-version-tags
          requires:
            - deploy-release

  nightly:
    triggers:
      - schedule:
          cron: "20 17 * * *"
          filters:
            branches:
              only: master
    jobs:
#      - build-macos:
#          <<: *never # temporarily disabled
      - nightly-automation:
          context: common
